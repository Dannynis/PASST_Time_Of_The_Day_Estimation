{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_wQZgxQ1x1-",
        "outputId": "26fc3190-4e6c-4749-ce74-585bb8c5f804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import shutil\n",
        "import os\n",
        "os.makedirs('./embeds', exist_ok=True)"
      ],
      "metadata": {
        "id": "SfuPRt3C16zl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing.dummy\n",
        "import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "pzru6l5u2DkH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Setup"
      ],
      "metadata": {
        "id": "vymBUtjF2Tz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_size = 768 #527\n",
        "passt_input_length_seconds = 30 #10"
      ],
      "metadata": {
        "id": "-D64avFw2XGE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data transfering"
      ],
      "metadata": {
        "id": "0XWLofjm2Fb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def helper(e):\n",
        "    name = e.split('/')[-1]\n",
        "    new = '/content/embeds/'+name\n",
        "\n",
        "    if os.path.exists(new):\n",
        "      return 1\n",
        "    shutil.copy(e,new)\n",
        "    return 1"
      ],
      "metadata": {
        "id": "3c6dCbW32HKE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = multiprocessing.dummy.Pool(30)"
      ],
      "metadata": {
        "id": "rWftbcgp2I4l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "while True:\n",
        "  try:\n",
        "    embeddings_dir_files = []\n",
        "    embeddings_dir = f\"/content/drive/MyDrive/Acoustic-Scene-Classification-and-Time-of-Day-Estimation/embeds_{passt_input_length_seconds}_sec\"\n",
        "    embeddings_dir_files += [str(x) for x in Path(embeddings_dir).rglob('*.pkl')]\n",
        "    embeddings_dir_files = list(set(embeddings_dir_files))\n",
        "    r = list(tqdm.tqdm(p.imap_unordered(helper,embeddings_dir_files),total=len(embeddings_dir_files)))\n",
        "  except:\n",
        "    import traceback\n",
        "    print(traceback.format_exc())\n",
        "    continue\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwPlo1y12m1L",
        "outputId": "67239ed2-03c3-4a96-ebfd-13e84688a53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 574/104814 [00:19<2:32:26, 11.40it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p.close()"
      ],
      "metadata": {
        "id": "AdktDJkX3We_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training setup"
      ],
      "metadata": {
        "id": "lpLYLDJF3eOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "import traceback\n",
        "\n",
        "import torch\n",
        "import soundfile as sf\n",
        "import skimage.measure\n",
        "import numpy as np\n",
        "\n",
        "import tqdm\n",
        "\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from io import BytesIO\n",
        "from torch.nn import Sequential,Linear,ELU,Sigmoid, BatchNorm1d, Dropout1d, ReLU, LeakyReLU"
      ],
      "metadata": {
        "id": "b-ho1qcO3gao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ibH5IgFrVGf"
      },
      "outputs": [],
      "source": [
        "def filename_to_time(file_name):\n",
        "    file_name = file_name.split('/')[-1].split('.')[0]\n",
        "    timestam_str = file_name.split(\"_\")[-1]\n",
        "    timestamp = float(int(timestam_str[0:2])*60 + int(timestam_str[2:4]) ) / 1440\n",
        "    return timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lrqQ5vYsAf0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "class EmbeddingsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,embeddings_dir, in_ram = False):\n",
        "\n",
        "        self.embeddings_dir_files = []\n",
        "        for x in Path(embeddings_dir).rglob('*'):\n",
        "            try:\n",
        "                self.embeddings_dir_files.append((filename_to_time(str(x)),str(x)))\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        self.in_ram = in_ram\n",
        "        self.times = []\n",
        "        self.embeds = {}\n",
        "        if vector_size==768:\n",
        "          self.passt_embedding_index = 1\n",
        "        elif vector_size==527:\n",
        "          self.passt_embedding_index = 0\n",
        "        else:\n",
        "          raise\n",
        "        self.good_files = []\n",
        "\n",
        "        for time,file_name in tqdm.tqdm(self.embeddings_dir_files[:]):\n",
        "              try:\n",
        "                if in_ram:\n",
        "                  with open(file_name,'rb') as f:\n",
        "                      embed = pickle.load(f)\n",
        "                  self.embeds[file_name] = embed[self.passt_embedding_index].cpu()\n",
        "                self.times.append(time)\n",
        "                self.good_files.append((time,file_name))\n",
        "              except:\n",
        "                  import traceback\n",
        "                  print(traceback.format_exc())\n",
        "                  print(file_name)\n",
        "\n",
        "        self.std = torch.std(torch.tensor(self.times))\n",
        "        self.mean = torch.mean(torch.tensor(self.times))\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        if self.embeds != []:\n",
        "          return len(self.embeds)\n",
        "        return len(self.good_files)\n",
        "\n",
        "    print('USING {} layer')\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        try:\n",
        "          'Generates one sample of data'\n",
        "          time, file_name = self.good_files[index]\n",
        "          if self.in_ram:\n",
        "            embed =  self.embeds[file_name]\n",
        "          else:\n",
        "            with open(file_name,'rb') as f:\n",
        "              embed = pickle.load(f)\n",
        "              embed = embed[self.passt_embedding_index]\n",
        "\n",
        "\n",
        "          return embed.reshape(-1),time\n",
        "        except EOFError as e:\n",
        "          print(e)\n",
        "          return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def col(batch):\n",
        "  try:\n",
        "    e = torch.stack([x[0] for x in batch if x != None])\n",
        "    t = torch.stack([torch.tensor(x[1]) for x in batch if x != None])\n",
        "    return e,t\n",
        "  except:\n",
        "    return torch.zeros(10)"
      ],
      "metadata": {
        "id": "ez7-D5vC4V6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rYibmuoT4X-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2qS_S90r_NA"
      },
      "outputs": [],
      "source": [
        "# embeddings_dir = \"/content/drive/MyDrive/Acoustic-Scene-Classification-and-Time-of-Day-Estimation/embeds3\"\n",
        "embeddings_dir = '/content/embeds'\n",
        "ds = EmbeddingsDataset(embeddings_dir,in_ram=True)\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(ds, [0.7, 0.15, 0.15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx33PgqlV3ML"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "times = []\n",
        "for d in tqdm.tqdm(train_set):\n",
        "  if d is not None:\n",
        "    times.append(d[1])\n",
        "times = torch.tensor(times)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEyKlp_-Y3GE"
      },
      "outputs": [],
      "source": [
        "h = plt.hist(times,bins=24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Sp98nlw2aR8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orXkp53I2uLS"
      },
      "outputs": [],
      "source": [
        "train_times = np.array(([x[1] * 24 for x in train_set]))\n",
        "weights=(1 / (h[0] / h[0].sum()))[np.floor(train_times).astype(np.int)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAiIXb9c2PGT"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import WeightedRandomSampler\n",
        "sampler = WeightedRandomSampler(weights, len(weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLqqADFbOJut"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "dl_train = torch.utils.data.DataLoader(train_set,batch_size=batch_size,num_workers=2,collate_fn=col,shuffle=True)\n",
        "dl_train_balanced = torch.utils.data.DataLoader(train_set,batch_size=batch_size,num_workers=2,collate_fn=col, sampler=sampler)\n",
        "\n",
        "test_dl_train = torch.utils.data.DataLoader(train_set,batch_size=256*20,num_workers=2,collate_fn=col,shuffle=False)\n",
        "dl_val = torch.utils.data.DataLoader(val_set,batch_size=256*20,num_workers=2,shuffle=False,collate_fn=col)\n",
        "\n",
        "dl_test = torch.utils.data.DataLoader(test_set,batch_size=256*20,num_workers=2,shuffle=False,collate_fn=col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhrMS7i9L5AC"
      },
      "outputs": [],
      "source": [
        "def CyclicL1Loss(output,target, max_val = 1):\n",
        "    criterion = lambda x,y: torch.abs(x-y)\n",
        "    return torch.stack([criterion(output, target), criterion(output-max_val, target), criterion(output+max_val, target)]).min(dim=0).values\n",
        "def CyclicMSELoss(output,target, max_val = 1):\n",
        "    criterion = lambda x,y: (x-y)**2\n",
        "    return torch.stack([criterion(output, target), criterion(output-max_val, target), criterion(output+max_val, target)]).min(dim=0).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-7qCNMawMmG"
      },
      "outputs": [],
      "source": [
        "criterion = CyclicMSELoss\n",
        "criterion_train = CyclicL1Loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hideen_size = 512\n",
        "\n",
        "num_hidden_layers = 3\n",
        "\n",
        "hidden_layers = []\n",
        "\n",
        "for num_hidden_layer in range(num_hidden_layers):\n",
        "   hidden_layers.append(Linear(hideen_size,hideen_size))\n",
        "   hidden_layers.append(torch.nn.Tanh())\n",
        "\n",
        "simple_dnn = nn.Sequential(*[Linear(768,hideen_size),torch.nn.Tanh()]+hidden_layers+[Linear(hideen_size,1),Sigmoid()]).cuda()\n",
        "\n",
        "print(f'amount of parameters {count_parameters(simple_dnn)}')"
      ],
      "metadata": {
        "id": "HZSzjkA45Y4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim = torch.optim.Adam(simple_dnn.parameters(), lr=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, 'min')"
      ],
      "metadata": {
        "id": "Eftfcbqp6ikR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_grad_norm(model):\n",
        "    grads = [\n",
        "        param.grad.detach().flatten()\n",
        "        for param in model.parameters()\n",
        "        if param.grad is not None\n",
        "    ]\n",
        "    norm = torch.cat(grads).norm()\n",
        "    return norm.item()"
      ],
      "metadata": {
        "id": "bfGRUskq6i-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AL58OCyL6krN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_iVfMd9P4Uw"
      },
      "outputs": [],
      "source": [
        "\n",
        "def eval_model_rmse(model,data_loader):\n",
        "  model.eval()\n",
        "  losses = []\n",
        "\n",
        "  for x in tqdm.tqdm_notebook(data_loader,total=len(data_loader.dataset)//data_loader.batch_size):\n",
        "      with torch.no_grad():\n",
        "        embed,target = x[0].cuda(),x[1].float().cuda()\n",
        "        output = model(embed).squeeze(-1).squeeze(-1)\n",
        "        loss = criterion(output, target)\n",
        "        losses.append(loss)\n",
        "  losses = torch.cat(losses)\n",
        "  # print(losses.shape)\n",
        "  model.train()\n",
        "  return (losses.mean() ** 0.5 * 1440, (losses ** 0.5).mean()* 1440)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHSrILrb_SlF"
      },
      "source": [
        "todo: try volume rms (std,mean) as simple features for comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VicZZ6ClyFWe"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBp-Rp-WeLuL"
      },
      "outputs": [],
      "source": [
        "# ls \"/content/drive/MyDrive/Acoustic-Scene-Classification-and-Time-of-Day-Estimation/runs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCEscubb8Hzk"
      },
      "outputs": [],
      "source": [
        "!pkill -f tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"/content/drive/MyDrive/Acoustic-Scene-Classification-and-Time-of-Day-Estimation/runs/tensorboard\" --bind_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OamTaGKxbFn0"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "model_time = datetime.datetime.now()\n",
        "save_dir ='/content/drive/MyDrive/Acoustic-Scene-Classification-and-Time-of-Day-Estimation/runs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_JssrHF6ICD"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter(log_dir=f\"{save_dir}/tensorboard/{model_time}\")\n",
        "\n",
        "n_iter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tz-GLYrz9Igk"
      },
      "outputs": [],
      "source": [
        "for x in dl_train:\n",
        "  pass\n",
        "writer.add_graph(simple_dnn,x[0].cuda())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDdswPTp4ITh"
      },
      "outputs": [],
      "source": [
        "scale_times = True\n",
        "eps = 0.000001\n",
        "label_smooth_scale = 0.0001\n",
        "use_label_smoothing = True\n",
        "print(f'Label smoothing turned to: {use_label_smoothing}')\n",
        "for epoch in tqdm.tqdm_notebook(range(100)):\n",
        "  losses = []\n",
        "  for x in dl_train_balanced:\n",
        "    simple_dnn.train()\n",
        "    embed,target = x[0].cuda(), x[1].cuda().float()\n",
        "    if use_label_smoothing:\n",
        "      target = target + torch.rand(len(target)).cuda()* label_smooth_scale\n",
        "    output = simple_dnn(embed).squeeze(-1)\n",
        "    optim.zero_grad()\n",
        "    loss = criterion_train(output, target).mean()# + gen_disc_loss\n",
        "    # kl_loss = torch.nn.functional.kl_div(torch.log(output).cuda(),target)\n",
        "    # loss += kl_loss + 0.1\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(simple_dnn.parameters(), 1)\n",
        "    optim.step()\n",
        "    losses.append(loss.item())\n",
        "    rtl = torch.tensor(losses).mean()** 0.5 * 1440\n",
        "    writer.add_scalar('Loss/running_train_loss', rtl, n_iter)\n",
        "    n_iter +=1\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    torch.save(simple_dnn,f'{save_dir}/models/768_logits_30_sec_3_{model_time}.ckpt')\n",
        "    train_loss, train_mae = eval_model_rmse(simple_dnn,test_dl_train)\n",
        "    print(f'train loss: {train_loss} \\n')\n",
        "    val_loss, val_mae = eval_model_rmse(simple_dnn,dl_val)\n",
        "    print(f'val loss: {val_loss} \\n')\n",
        "    scheduler.step(val_loss)\n",
        "    grad_norm = get_grad_norm(simple_dnn)\n",
        "    writer.add_scalar('Loss/train', train_loss, n_iter)\n",
        "    writer.add_scalar('Loss/test', val_loss, n_iter)\n",
        "    writer.add_scalar('lr',scheduler.optimizer.param_groups[0]['lr'],n_iter)\n",
        "    writer.add_scalar('grad_norm',grad_norm,n_iter)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_mae = eval_model_rmse(simple_dnn,dl_test)\n",
        "print(f'test loss: {val_loss} \\n')"
      ],
      "metadata": {
        "id": "0UohYz-S8W5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Unseen Dataset (Only 30 seconds setup uvailable)"
      ],
      "metadata": {
        "id": "yHy6lcBT9Ikr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "DkWYxTrO92aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p= multiprocessing.dummy.Pool(30)\n",
        "os.makedirs('./embeds_test', exist_ok=True)\n",
        "def helper(e):\n",
        "    name = e.split('/')[-1]\n",
        "    new = '/content/embeds_test/'+name\n",
        "\n",
        "    if os.path.exists(new):\n",
        "      return 1\n",
        "    shutil.copy(e,new)\n",
        "    return 1\n",
        "\n",
        "\n",
        "while True:\n",
        "  try:\n",
        "    embeddings_dir_files = []\n",
        "    embeddings_dir = \"/content/drive/MyDrive/Acoustic-Scene-Classification-and-Time-of-Day-Estimation/after_corona_30sec\"\n",
        "    embeddings_dir_files += [str(x) for x in Path(embeddings_dir).rglob('*.pkl')]\n",
        "    embeddings_dir_files = list(set(embeddings_dir_files))\n",
        "    r = list(tqdm.tqdm(p.imap_unordered(helper,embeddings_dir_files),total=len(embeddings_dir_files)))\n",
        "  except:\n",
        "    import traceback\n",
        "    print(traceback.format_exc())\n",
        "    continue\n",
        "  break"
      ],
      "metadata": {
        "id": "fcBXruob9L13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dir = '/content/embeds_test'\n",
        "ds_enroll = EmbeddingsDataset(embeddings_dir,in_ram=True)\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "2qV5d3OD9SSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "dfs = []\n",
        "\n",
        "save_dir ='/content/drive/MyDrive/Acoustic-Scene-Classification-and-Time-of-Day-Estimation/runs'\n",
        "model_ckpts = glob.glob(save_dir+'/models/*')\n",
        "for i,model_path in enumerate(model_ckpts):\n",
        "  if '768_logits_30_sec_3_' not in model_path:\n",
        "    continue\n",
        "  print(model_path)\n",
        "  model = torch.load(model_path)\n",
        "  model.eval()\n",
        "\n",
        "  test_dl = torch.utils.data.DataLoader(ds_enroll)\n",
        "  target = []\n",
        "  output = []\n",
        "  vecs = []\n",
        "  for x in tqdm.tqdm_notebook(test_dl):\n",
        "    target.append(x[1])\n",
        "    with torch.no_grad():\n",
        "      r = model(x[0].cuda())\n",
        "    output.append(r.cpu())\n",
        "    vecs.append(x[0])\n",
        "\n",
        "  target = torch.cat(target) * 1440\n",
        "  output = torch.cat(output).squeeze(1) * 1440\n",
        "\n",
        "  vecs = torch.cat(vecs)\n",
        "  import pandas as pd\n",
        "  df = pd.DataFrame(torch.stack([output,target, torch.ones_like(target)*len(dfs)]).T,columns=['out','trg','model_type'])\n",
        "  df['loss'] = criterion(output, target, max_val=1440)\n",
        "  df = df.sort_values('trg')\n",
        "  dfs.append(df)\n",
        "  print(df.loss.mean() ** 0.5)\n"
      ],
      "metadata": {
        "id": "aZ9iMZIf9f3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.histogram(df,'trg',histnorm='probability')"
      ],
      "metadata": {
        "id": "AoZf9Cnv9xCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.histogram(df,'out',histnorm='probability')"
      ],
      "metadata": {
        "id": "UiULgtwd99wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.scatter(df,'trg','out')"
      ],
      "metadata": {
        "id": "8PMf2sEx9_2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchview"
      ],
      "metadata": {
        "id": "8UJDkQ-z-NLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchview import draw_graph"
      ],
      "metadata": {
        "id": "wgYVH43n-KmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_graph = draw_graph(model, input_size=(1,768), expand_nested=True, save_graph=True)\n",
        "model_graph.visual_graph\n"
      ],
      "metadata": {
        "id": "o1angAuq-BfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loss.mean() ** 0.5"
      ],
      "metadata": {
        "id": "sVnqQot5-oDm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}